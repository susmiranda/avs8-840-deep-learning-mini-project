{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.data.fsd50k_dataset import SpectrogramDataset\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The commented out inputs can still be included when creating the dataset\n",
    "audio_config = {'feature': 'melspectrogram',\n",
    "                # n_fft: 511\n",
    "                # win_len:\n",
    "                # hop_len:\n",
    "                # normalize:\n",
    "                'sample_rate': 22050,\n",
    "                'min_duration': 1}\n",
    "manifest_path = r\"C:\\Users\\vismi\\Documents\\datasets\\FSD50K\\manifests\\tr.csv\" # Change this to your local path\n",
    "labels_map = r\"C:\\Users\\vismi\\Documents\\datasets\\FSD50K\\manifests\\lbl_map.json\" # Change this to your local path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 520966/520966 [00:10<00:00, 50323.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([520966, 200])\n"
     ]
    }
   ],
   "source": [
    "# Make the dataset and dataloader\n",
    "dataset = SpectrogramDataset(manifest_path, labels_map, audio_config)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 200])\n",
      "torch.Size([5, 96, 101])\n",
      "torch.Size([5, 1, 96, 101])\n"
     ]
    }
   ],
   "source": [
    "# Plot a random element of the dataset\n",
    "spectrograms, targets = next(iter(dataloader))\n",
    "print(targets.shape)\n",
    "print(spectrograms.shape)\n",
    "# plt.imshow(spectrogram[0])\n",
    "# plt.show()\n",
    "\n",
    "# # Add the channels dimension which is missing and usually expected from vision transformers\n",
    "input = spectrograms.expand(1, -1, -1, -1) # Create an extra empty dimension\n",
    "input = input.permute(1, 0, 2, 3) # Permute so we have Batch - Channel - Width - Height\n",
    "# input = input.to(device)\n",
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.KWT import KWT\n",
    "# Input arguments to Holger's vision transformer. The commented out lines can still be added but are optional.\n",
    "# The input resolution needs to match the spectrogram. Either change the dataset to match the model or the model to match the dataset.\n",
    "# The patch res needs to divide the input resolution.\n",
    "model_harams = {\n",
    "        'input_res': [96, 101],\n",
    "        'patch_res': [96, 1],\n",
    "        'num_classes': 3,\n",
    "        'mlp_dim': 256,\n",
    "        'dim': 64,\n",
    "        'heads': 1,\n",
    "        'depth': 12\n",
    "        # dropout: 0.0\n",
    "        # emb_dropout: 0.1\n",
    "        # pre_norm: False\n",
    "        # pool: mean\n",
    "}\n",
    "# Create the model\n",
    "model = KWT(**model_harams)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.ssformer import SSTransformer\n",
    "# This is the self supervised transformer.\n",
    "# It is based on the KWT model above. The model_embed_dim needs to match 'dim' from earlier\n",
    "ss_model_harams = {\n",
    "        'encoder': model,\n",
    "        'model_embed_dim': 64,\n",
    "        'ema_decay': 0.999,\n",
    "        'ema_end_decay': 0.9999,\n",
    "        'ema_anneal_end_step': 1000,\n",
    "        'average_top_k_layers': 8, \n",
    "        'normalize_targets': True\n",
    "}\n",
    "\n",
    "transformer = SSTransformer(**ss_model_harams)\n",
    "transformer.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 102, 64]) torch.Size([1, 1, 102, 64])\n"
     ]
    }
   ],
   "source": [
    "# During self supervised training we give both the teacher and the student the same inputs.\n",
    "# In practice the student and teacher are different models so their outputs will be different.\n",
    "# x is the final latent state of the student (the KWT model)\n",
    "# y is the averaged out latent states of the teacher (EMA KWT)\n",
    "x, y = transformer(input, input)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of criterion output: torch.Size([1, 1, 102, 64])\n",
      "After first sum: torch.Size([1, 1, 102])\n",
      "After second sum: torch.Size([]), Value: 135943.15625\n",
      "Final loss after scale: 16992.89453125\n",
      "tensor(16992.8945, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# The loss is calculated between the two latent states\n",
    "scale = math.sqrt(y.size(dim=-1))\n",
    "criterion = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "print(f'Shape of criterion output: {criterion(x.float(), y.float()).shape}')\n",
    "print(f'After first sum: {criterion(x.float(), y.float()).sum(dim=-1).shape}')\n",
    "print(f'After second sum: {criterion(x.float(), y.float()).sum(dim=-1).sum().shape}, Value: {criterion(x.float(), y.float()).sum(dim=-1).sum()}')\n",
    "loss = criterion(x.float(), y.float()).sum(dim=-1).sum().div(scale)\n",
    "print(f'Final loss after scale: {loss}')\n",
    "loss.backward()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-06\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0005\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(transformer.parameters(), \n",
    "                       lr=0.0005,\n",
    "                       betas=(0.9, 0.98),\n",
    "                       eps=0.000001,\n",
    "                       )\n",
    "print(optimizer)\n",
    "optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
